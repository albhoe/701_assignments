{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment was copleted using tutorials on the GeeksforGeeks website, and with VSCode's inline generative code completion too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/alber/AppData/Local/Microsoft/WindowsApps/python3.13.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%%python3 --version\n",
    "\n",
    "# create a virtual environment and put it in .venv\n",
    "%python3 -m venv .venv\n",
    "\n",
    "# start the environment\n",
    "%source .venv/bin/activate\n",
    "\n",
    "%pip install -r requirements.txt\n",
    "%pip install otter-grader\n",
    "\n",
    "# start vscode in the current directory if you are using that\n",
    "%code ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Introduction to Pandas and Scikit-Learn\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python. It provides data structures like DataFrames and Series that allow for efficient handling of structured data. Pandas is particularly useful for tasks such as reading and writing data in various formats, data cleaning, merging datasets, and performing complex operations on data.\n",
    "\n",
    "Scikit-learn, on the other hand, is a machine learning library for Python. It provides a wide range of supervised and unsupervised learning algorithms, as well as tools for model selection, evaluation, and preprocessing. Scikit-learn is designed to be user-friendly and efficient, making it a popular choice for both beginners and experienced data scientists.\n",
    "\n",
    "Together, Pandas and Scikit-learn form a powerful combination for data analysis and machine learning tasks. Pandas is often used to prepare and manipulate data, which can then be fed into Scikit-learn models for training and prediction.\n",
    "\n",
    "In this assignment, we'll start with the fundamentals of data loading/manipulation in pandas, then move on to basics of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the **Census Income** dataset which is available on the [UCI ML Dataset Page](https://archive.ics.uci.edu/dataset/20/census+income).\n",
    "\n",
    "The goal is to predict whether a person's income was greater than $50K based on 1994 census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick look at the dataset. We'll use the .head() function to view the first 5 records of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Feel free to refer to the course notes on [pandas](https://tools4ds.github.io/DS701-Course-Notes/02B-Pandas.html) for the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1a**: Write a function `get_rows_and_columns` that takes as input a CSV filename, loads this file into a Pandas dataframe, and returns a tuple of the number of rows and columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def get_rows_and_columns(file_path):\n",
    "    df = pd.read_csv(file_path) \n",
    "    return df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "get_rows_and_columns('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 1b**: Write a function `compute_missing_percentage` that converts '?' to `pd.NA` and returns the percentage of missing data (i.e., NaNs) for each column in the dataset.\n",
    "\n",
    "The term `pd.NA` is the way to represent [missing values](https://pandas.pydata.org/docs/reference/missing_value.html) (not available) in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_missing_percentage(df):\n",
    "    df = df.map(lambda x: pd.NA if x=='?' else x)\n",
    "    rows,cols = df.shape\n",
    "    counts = df.count(axis = 0)\n",
    "    return counts.apply (lambda x: (1-(x/rows))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "compute_missing_percentage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1c**: Write a function `unique_occupation` that returns the number of unique occupation present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def unique_occupation(df):\n",
    "    return df['occupation'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "unique_occupation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1d**: Write a function `categorical_column_with_max_unique_values` that identifies and returns the index of the **column with maximum number of distinct categorical values** in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def categorical_column_with_max_unique_values(df):\n",
    "    cats = df.loc[:,['workclass','education','occupation','marital-status','relationship','race','native-country']]\n",
    "    uniques = cats.nunique(axis = 0)\n",
    "    return uniques.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "categorical_column_with_max_unique_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 2: Exploratory data analysis and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2a**: Write a function `plot_categorical_distribution` to plot the distribution of the column 'education' as a histogram.\n",
    "\n",
    "You can use Pandas `.plot()` method for this. Look at the DataFrame `.value_counts` method as well. See class examples for how to add labels and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_distribution(df):\n",
    "    df['education'].value_counts(ascending=True).plot(kind='bar',title='Education Distribution',xlabel='Education Level',ylabel='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_categorical_distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2b**: Write a function `plot_age_hours_scatter` that creates a scatter plot of 'age' vs 'hours-per-week', coloring points by 'income'.\n",
    "\n",
    "You'll want to look at MatPlotLib's `pyplot.scatter()` for this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_age_hours_scatter(df):\n",
    "    lowdf = df[df['income'] == '<=50K']\n",
    "    highdf = df[df['income'] == '>50K']\n",
    "    plt.scatter(lowdf['age'],lowdf['hours-per-week'],s=4,color='blue',label='<=50K')\n",
    "    plt.scatter(highdf['age'],highdf['hours-per-week'],s=4,color='green',label='>50K')\n",
    "    plt.title('Age vs Hours per Week')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Hours per Week')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_age_hours_scatter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2c**: Write a function `plot_income_by_marital_status` which plots a stacked bar chart that shows the proportion of income levels for each 'marital-status' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_income_by_marital_status(df):\n",
    "    return df.groupby('marital-status')['income'].value_counts().unstack().plot(kind='bar',stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_income_by_marital_status(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Part 3: Advanced Pandas Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3a**: Write a function `education_stats` that returns a dataframe with mean 'age' and median 'hours-per-week' categorized on the 'education' level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def education_stats(df):\n",
    "    res =  df.groupby('education').agg({'age':'mean', 'hours-per-week':'median'})\n",
    "    res.reset_index(inplace=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3b**: Write a function `calculate_most_popular_occupation` that returns a dataframe of the most popular occupation for each 'native-country' and order them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_most_popular_occupation(df):\n",
    "    counts = df.groupby('native-country')['occupation']\n",
    "\n",
    "    occupations = pd.Series(index=df['native-country'].unique(),dtype=object)\n",
    "    for country in occupations.index:\n",
    "       occupations[country] = counts.get_group(country).value_counts().idxmax()\n",
    "    occupations = occupations.to_frame()\n",
    "    occupations.columns = pd.Index(['occupation'],dtype='object')\n",
    "    occupations.index.name = 'native-country'\n",
    "    occupations.reset_index(inplace=True)\n",
    "    return occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "calculate_most_popular_occupation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3c**: Write a function `workclass_by_income` that returns a dataframe of the top 5 workclass with the highest number of people having income >50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def workclass_by_income(df):\n",
    "     highIncome = df[df['income'] == \">50K\"]\n",
    "     workclass = highIncome['workclass']\n",
    "     workcounts = workclass.value_counts()\n",
    "     res = workcounts.to_frame()\n",
    "     res.columns = pd.Index(['count'],dtype='object')\n",
    "     res.reset_index(inplace=True)\n",
    "     return res\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "workclass_by_income(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO RUN THIS CELL!\n",
    "\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "df_new = df.drop(columns=['native-country', 'fnlwgt']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll implement [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) using scikit-learn. Logistic regression is used when trying to predict a binary outcome (0 or 1, True or False, etc.) We will go over the details of logistic regression in details later in the course. \n",
    "\n",
    "Here, we will try to predict income (>50k or <= 50k>) and follow standard ML procedures for data pre-processing. You can use scikit-learn's documentation, [the lecture notes on scikit-learn](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html) or online resources for guidance. \n",
    "\n",
    "#### From here on use the 'df_new' variable instead of 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We saw in lecture that models are trained on the 'training' set and evaluated on unseen data on the 'testing' set. The dataset has 'feature' (`X_train`, `X_test`) and the 'outcome' (`y_train`, `y_test`) variables. \n",
    "\n",
    "**Question 4a:** Write a function called `split_data` that takes a dataframe as its only parameter, splits it into training and test splits and returns them. Use 20% for the testing set. \n",
    "\n",
    "Use `train_test_split` to produce the splits. Provide a `random_state` of 42 for reproducibility.\n",
    "\n",
    "`split_data` should return 4 things: X_train, X_test y_train and y_test. To do that, you need to pass in the X *and* the y (income column) to `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    X = df_new.loc[:,df_new.columns != 'income']\n",
    "    return train_test_split(X,df_new['income'],random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 4b**: Write a function `preprocess_data` that takes X_train, y_train, X_test, and y_test as input (the splits we created earlier!) and does the following:\n",
    "\n",
    " - Scale the *numerical* columns using sklearn's `MinMaxScaler` to the range [0,1] for both train and test sets\n",
    "  \n",
    " - Replace \"<=50K\" with 0 and \">50K\" with 1 in both y_train and y_test\n",
    "\n",
    " - One-hot encode the categorical columns for both train and test sets. Check the next cell for some hints! \n",
    "  \n",
    "The function should then return the preprocessed X_train, y_train, X_test, and y_test\n",
    "\n",
    "Refer to the material below and [sklearn course notes](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html#prepare-the-dataset) for help! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One hot encoding is a way of turning textual data into numbers, so that models can work with them. \n",
    "\n",
    "Pandas has a method called `pd.get_dummies()` that can do one-hot encoding. \n",
    "\n",
    "Let's illustrate with an example.  Let's say we are describing 4 people, each\n",
    "with attribute 'Gender' and 'City' where they reside.\n",
    "\n",
    "Create a dictionary with 'City' and 'Gender' keys, each with a length 4 list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Sample DataFrame with categorical columns\n",
    "data = {'City': ['New York', 'Los Angeles', 'New York', 'Chicago'],\n",
    "        'Gender': ['Female', 'Male', 'Male', 'Female']}\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can give that to Pandas `pd.DataFrame()` and it will create a DataFrame with\n",
    "a City column and a Gender column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we can call `pd.get_dummies` with the dataframe and it will convert each\n",
    "categorical column into a set of columns with each category and column entries\n",
    "of True or False (e.g. 1 or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['City', 'Gender'])\n",
    "# notice how I'm passing in the columns -- you should do this too! Hint: you wrote a function for this earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "   Notice how now every `City` value has its own column, and that every row with a city has a 1 for that city (row 1 in the old dataframe has New York for the `City`, and row in the new dataframe has a 1 for `City_New York`). Everywhere else you have a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def income2int(income):\n",
    "    if income == '<=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    num_cols = ['age','educational-num','capital-gain','capital-loss','hours-per-week']\n",
    "    cat_cols = ['workclass','education','occupation','marital-status','relationship','race','gender']\n",
    "\n",
    "    X_train_num = scaler.fit_transform(X_train[num_cols])\n",
    "    X_train_num = pd.DataFrame(X_train_num,columns=num_cols,index=X_train.index)\n",
    "    X_test_num = scaler.transform(X_test[num_cols])\n",
    "    X_test_num = pd.DataFrame(X_test_num,columns=num_cols,index=X_test.index)  \n",
    "\n",
    "    X_train_cat = pd.get_dummies(X_train[cat_cols], columns= cat_cols)\n",
    "    X_test_cat = pd.get_dummies(X_test[cat_cols], columns= cat_cols)\n",
    "\n",
    "    X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "    X_test = pd.concat([X_test_num, X_test_cat], axis=1)\n",
    "\n",
    "    y_train = y_train.map(income2int)\n",
    "    y_test = y_test.map(income2int)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df_new)\n",
    "X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's get to training! Remember, we're trying to predict whether income is more then 50k (>50k), or less than or equal to (<=50k).\n",
    "\n",
    "**Question 4c:** Write a function called train_model that takes the training splits (X_train and y_train) as its parameters. \n",
    "\n",
    "- Initialize the logistic regression model\n",
    "- Fit it to our data. (Training step)\n",
    "\n",
    "At the end, return the fitted model. \n",
    "\n",
    "You can refer to [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    reg = LogisticRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's evaluate the performance of our model! \n",
    "\n",
    "**Question 4d:** Write a function called evaluate_model that takes the fitted model and `X_test`, `y_test` as parameters, runs the model on the testing features (`X_test`) and returns the *accuracy score* of the predictions against the ground truth (`y_test`). \n",
    "\n",
    "You can refer to [sklearn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    p = model.predict(X_test)\n",
    "    return accuracy_score(y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Execute all cells and save the notebook before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_rows_and_columns('adult.csv') == (48842, 15)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> unique_occupation(df) == 15\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_occupation(df) == 13\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_occupation(df) == 14\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> categorical_column_with_max_unique_values(df) == 'native-country'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> categorical_column_with_max_unique_values(df) == 'workclass'\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> categorical_column_with_max_unique_values(df) == 'occupation'\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(education_stats(df)) == 16\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(education_stats(df).columns) == {'education', 'age', 'hours-per-week'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(education_stats(df).iloc[0]['age'], 37.902808))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(education_stats(df).iloc[1]['hours-per-week'] == 40.0)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> int(education_stats(df)['hours-per-week'].value_counts().get(40.0, 0)) == 14\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert education_stats(df).iloc[13]['education'] == 'Preschool'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert education_stats(df).iloc[7]['education'] == 'Assoc-acdm'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'United-States']['occupation'].values[0] == 'Exec-managerial'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'India']['occupation'].values[0] == 'Prof-specialty'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'England']['occupation'].values[0] == 'Craft-repair'\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'Germany']['occupation'].values[0] == 'Exec-managerial'\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Private']['count'].values[0] == 7387)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Federal-gov']['count'].values[0] == 561)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Local-gov']['count'].values[0] == 920)\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Self-emp-not-inc']['count'].values[0] == 565)\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_split_data():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     output = split_data(df_new)\n...     assert len(output) == 4, 'split_data() should return 4 things. Make sure you pass both the X and the y to train_test_split.'\n...     (X_train, X_test, y_train, y_test) = output\n...     assert len(X_train) + len(X_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert len(y_train) + len(y_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert np.all(X_train.columns == X_test.columns), 'The columns in X_train and X_test are not the same.'\n...     assert len(X_train) > 0 and len(X_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n...     assert len(y_train) > 0 and len(y_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n>>> test_split_data()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_correct_X():\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         (X_train, X_test, y_train, y_test) = split_data(df_new)\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(X_train.columns == X_test.columns), 'The columns in X_train and X_test are not the same.'\n...     assert np.allclose(np.mean(X_train), np.mean(X_test), atol=0.01), 'The mean of every column is not the same in X_train and X_test.'\n...     assert np.all((X_train >= 0) & (X_train <= 1)), 'X_train has values that are not between 0 and 1.'\n...     assert np.all((X_test >= 0) & (X_test <= 1)), 'X_test has values that are not between 0 and 1.'\n...     assert np.all((np.mean(X_train) >= 0) & (np.mean(X_train) <= 1)), 'X_train has columns with mean values not between 0 and 1.'\n...     assert np.all((np.mean(X_test) >= 0) & (np.mean(X_test) <= 1)), 'X_test has columns with mean values not between 0 and 1.'\n>>> def test_correct_y():\n...     splits = train_test_split(df_new.drop(columns='income'), df_new['income'], test_size=0.2, random_state=42)\n...     (X_train, X_test, y_train, y_test) = splits\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(y_train.isin([0, 1])), 'y_train has values that are not 0 or 1.'\n...     assert np.all(y_test.isin([0, 1])), 'y_test has values that are not 0 or 1.'\n>>> test_correct_X()\n>>> test_correct_y()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_train_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     (X_train, X_test, y_train, y_test) = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore')\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...         model = train_model(X_train, y_train)\n...     return isinstance(model, LogisticRegression)\n>>> test_train_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_evaluate_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     (X_train, X_test, y_train, y_test) = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore')\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...         model = train_model(X_train, y_train)\n...         model = train_model(X_train, y_train)\n...         accuracy = evaluate_model(model, X_test, y_test)\n...     return bool(np.isclose(accuracy, 0.85, atol=0.1))\n>>> test_evaluate_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
